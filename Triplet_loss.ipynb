{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triplet Loss with Online Triplet Mining\n",
    "\n",
    "source: \n",
    "1. https://github.com/bukhari-utp/Face-identification-with-cnn-triplet-loss\n",
    "2. https://github.com/bukhari-utp/siamese-triplet (Siamese and triplet networks with online pair/triplet mining in PyTorch)\n",
    "3. siamese-transfer-learning/siamese_dogs_vs_cats_vgg16.ipynb\n",
    "\n",
    "- seems doesn't work, no improvement (see the source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train a cnn to extract the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "import numpy as np\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.layers import Dense, Lambda, Input, merge, Conv2D, Activation, Dropout, MaxPooling2D, Flatten, GlobalMaxPooling2D, BatchNormalization\n",
    "import keras.backend as K\n",
    "\n",
    "import dlib\n",
    "\n",
    "from IPython.display import Image as image_disp\n",
    "\n",
    "import skimage.transform as tr\n",
    "\n",
    "from enum import Enum\n",
    "\n",
    "import os.path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceDetector:\n",
    "    def __init__(self):\n",
    "        self.detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "    def detect_faces(self,\n",
    "                     image, *,\n",
    "                     upscale_factor=1,\n",
    "                     greater_than=None,\n",
    "                     get_top=None):\n",
    "\n",
    "        face_rects = list(self.detector(image, upscale_factor))\n",
    "\n",
    "        if greater_than is not None:\n",
    "            face_rects = list(filter(lambda r:\n",
    "                              r.height() > greater_than and r.width() > greater_than,\n",
    "                              face_rects))\n",
    "\n",
    "        face_rects.sort(key=lambda r: r.width() * r.height(), reverse=True)\n",
    "\n",
    "        if get_top is not None:\n",
    "            face_rects = face_rects[:get_top]\n",
    "\n",
    "        return face_rects\n",
    "\n",
    "\n",
    "class FaceAlignMask(Enum):\n",
    "    INNER_EYES_AND_BOTTOM_LIP = [39, 42, 57]\n",
    "    OUTER_EYES_AND_NOSE = [36, 45, 33]\n",
    "\n",
    "\n",
    "class FaceAligner:\n",
    "    def __init__(self,\n",
    "                 dlib_predictor_path,\n",
    "                 face_template_path):\n",
    "        self.predictor = dlib.shape_predictor(dlib_predictor_path)\n",
    "        self.face_template = np.load(face_template_path)\n",
    "\n",
    "    def get_landmarks(self,\n",
    "                      image,\n",
    "                      face_rect):\n",
    "        points = self.predictor(image, face_rect)\n",
    "        return np.array(list(map(lambda p: [p.x, p.y], points.parts())))\n",
    "\n",
    "    def align_face(self,\n",
    "                   image,\n",
    "                   face_rect, *,\n",
    "                   dim=96,\n",
    "                   border=0,\n",
    "                   mask=FaceAlignMask.INNER_EYES_AND_BOTTOM_LIP):\n",
    "        mask = np.array(mask.value)\n",
    "\n",
    "        landmarks = self.get_landmarks(image, face_rect)\n",
    "        proper_landmarks = border + dim * self.face_template[mask]\n",
    "        A = np.hstack([landmarks[mask], np.ones((3, 1))]).astype(np.float64)\n",
    "        B = np.hstack([proper_landmarks, np.ones((3, 1))]).astype(np.float64)\n",
    "        T = np.linalg.solve(A, B).T\n",
    "\n",
    "        wrapped = tr.warp(image,\n",
    "                          tr.AffineTransform(T).inverse,\n",
    "                          output_shape=(dim + 2 * border, dim + 2 * border),\n",
    "                          order=3,\n",
    "                          mode='constant',\n",
    "                          cval=0,\n",
    "                          clip=True,\n",
    "                          preserve_range=True)\n",
    "\n",
    "        return wrapped\n",
    "\n",
    "    def align_faces(self,\n",
    "                    image,\n",
    "                    face_rects,\n",
    "                    *args,\n",
    "                    **kwargs):\n",
    "        result = []\n",
    "\n",
    "        for rect in face_rects:\n",
    "            result.append(self.align_face(image, rect, *args, **kwargs))\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "def clip_to_range(img):\n",
    "    return img / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "GREATER_THAN = 32\n",
    "BATCH_SIZE = 128\n",
    "IMSIZE = 217\n",
    "IMBORDER = 5\n",
    "\n",
    "def build_my_cnn(dim, n_class, n_channel):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(BatchNormalization(input_shape=(dim, dim, 1)))\n",
    "    \n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(128,kernel_size=(3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(32, kernel_size=(3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(GlobalMaxPooling2D())\n",
    "    \n",
    "    model.add(Dense(64)) #512\n",
    "    model.add(Activation('relu'))    \n",
    "    \n",
    "    model.add(Dense(n_class))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def triplet_loss(y_true, y_pred):\n",
    "    return -K.mean(K.log(K.sigmoid(y_pred)))\n",
    "\n",
    "def triplet_merge(inputs):\n",
    "    a, p, n = inputs\n",
    "    return K.sum(a * (p - n), axis=1)\n",
    "\n",
    "def triplet_merge_shape(input_shapes):\n",
    "    return (input_shapes[0][0], 1)\n",
    "\n",
    "def build_tpe(n_in, n_out, W_pca=None):\n",
    "    a = Input(shape=(n_in,))\n",
    "    p = Input(shape=(n_in,))\n",
    "    n = Input(shape=(n_in,))\n",
    "\n",
    "    if W_pca is None:\n",
    "        W_pca = np.zeros((n_in, n_out))\n",
    "\n",
    "    base_model = Sequential()\n",
    "    base_model.add(Dense(n_out, input_dim=n_in, bias=False, weights=[W_pca], activation='linear'))\n",
    "    base_model.add(Lambda(lambda x: K.l2_normalize(x, axis=1)))\n",
    "\n",
    "    a_emb = base_model(a)\n",
    "    p_emb = base_model(p)\n",
    "    n_emb = base_model(n)\n",
    "\n",
    "    e = merge([a_emb, p_emb, n_emb], mode=triplet_merge, output_shape=triplet_merge_shape)\n",
    "\n",
    "    model = Model(input=[a, p, n], output=e)\n",
    "    predict = Model(input=a, output=a_emb)\n",
    "\n",
    "    model.compile(loss=triplet_loss, optimizer='rmsprop')\n",
    "\n",
    "    return model, predict\n",
    "\n",
    "class Bottleneck:\n",
    "    def __init__(self, model, layer):\n",
    "        self.fn = K.function([model.layers[0].input, K.learning_phase()], [model.layers[layer].output])\n",
    "\n",
    "    def predict(self, data_x, batch_size=32, learning_phase=False):\n",
    "        n_data = len(data_x)\n",
    "        n_batches = n_data // batch_size + (0 if n_data % batch_size == 0 else 1)\n",
    "\n",
    "        result = None\n",
    "\n",
    "        learning_phase = 1 if learning_phase else 0\n",
    "\n",
    "        for i in range(n_batches):\n",
    "            batch_x = data_x[i * batch_size:(i + 1) * batch_size]\n",
    "            batch_y = self.fn([batch_x, 0])[0]\n",
    "\n",
    "            if result is None:\n",
    "                result = batch_y\n",
    "            else:\n",
    "                result = np.vstack([result, batch_y])\n",
    "\n",
    "        return result\n",
    "\n",
    "class FaceVerificator:\n",
    "    def __init__(self, model_dir):\n",
    "        self._model_dir = model_dir\n",
    "\n",
    "        self._model_files = {\n",
    "            'shape_predictor': os.path.join(model_dir, 'shape_predictor_68_face_landmarks.dat'),\n",
    "            'face_template': os.path.join(model_dir, 'face_template.npy'),\n",
    "            'mean': os.path.join(model_dir, 'mean.npy'),\n",
    "            'stddev': os.path.join(model_dir, 'stddev.npy'),\n",
    "            'cnn_weights': os.path.join(model_dir, 'weights_cnn.h5'),\n",
    "            'tpe_weights': os.path.join(model_dir, 'weights_tpe.h5'),\n",
    "        }\n",
    "\n",
    "    def initialize_model(self):\n",
    "        self._mean = np.load(self._model_files['mean'])\n",
    "        self._stddev = np.load(self._model_files['stddev'])\n",
    "        self._fd = FaceDetector()\n",
    "        self._fa = FaceAligner(self._model_files['shape_predictor'],\n",
    "                               self._model_files['face_template'])\n",
    "        cnn = build_my_cnn(227, 24)\n",
    "        cnn.load_weights(self._model_files['cnn_weights'])\n",
    "        self._cnn = Bottleneck(cnn, ~1)\n",
    "        _, tpe = build_tpe(24, 24)\n",
    "        tpe.load_weights(self._model_files['tpe_weights'])\n",
    "        self._tpe = tpe\n",
    "\n",
    "    def normalize(self, img):\n",
    "        img = clip_to_range(img)\n",
    "        return (img - self._mean) / self._stddev\n",
    "\n",
    "    def process_image(self, img):\n",
    "        face_rects = self._fd.detect_faces(img, upscale_factor=2, greater_than=GREATER_THAN)\n",
    "\n",
    "        if not face_rects:\n",
    "            return []\n",
    "\n",
    "        faces = self._fa.align_faces(img, face_rects, dim=IMSIZE, border=IMBORDER)\n",
    "        faces = list(map(self.normalize, faces))\n",
    "\n",
    "        faces_y = self._cnn.predict(faces, batch_size=BATCH_SIZE)\n",
    "        faces_y = self._tpe.predict(faces_y, batch_size=BATCH_SIZE)\n",
    "\n",
    "        return list(zip(face_rects, faces_y))\n",
    "\n",
    "    def compare_many(self, dist, xs, ys):\n",
    "        xs = np.array(xs)\n",
    "        ys = np.array(ys)\n",
    "        scores = xs @ ys.T\n",
    "        return scores, scores > dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(data_y, protocol):\n",
    "    data_y = data_y / np.linalg.norm(data_y, axis=1)[:, np.newaxis]\n",
    "    scores = data_y @ data_y.T\n",
    "\n",
    "    return scores[protocol], scores[np.logical_not(protocol)]\n",
    "\n",
    "\n",
    "def calc_metrics(targets_scores, imposter_scores):\n",
    "    min_score = np.minimum(np.min(targets_scores), np.min(imposter_scores))\n",
    "    max_score = np.maximum(np.max(targets_scores), np.max(imposter_scores))\n",
    "\n",
    "    n_tars = len(targets_scores)\n",
    "    n_imps = len(imposter_scores)\n",
    "\n",
    "    N = 100\n",
    "\n",
    "    fars = np.zeros((N,))\n",
    "    frrs = np.zeros((N,))\n",
    "    dists = np.zeros((N,))\n",
    "\n",
    "    min_gap = float('inf')\n",
    "    eer = 0\n",
    "\n",
    "    for i, dist in enumerate(np.linspace(min_score, max_score, N)):\n",
    "        far = len(np.where(imposter_scores > dist)[0]) / n_imps\n",
    "        frr = len(np.where(targets_scores < dist)[0]) / n_tars\n",
    "        fars[i] = far\n",
    "        frrs[i] = frr\n",
    "        dists[i] = dist\n",
    "\n",
    "        gap = np.abs(far - frr)\n",
    "\n",
    "        if gap < min_gap:\n",
    "            min_gap = gap\n",
    "            eer = (far + frr) / 2\n",
    "\n",
    "    return eer, fars, frrs, dists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_train: 60000\n",
      "n_test: 10000\n",
      "n_subjects: 10\n"
     ]
    }
   ],
   "source": [
    "OUT_DIR = '../output/DR-Net_triplet_loss'\n",
    "if not os.path.exists(OUT_DIR):\n",
    "    os.mkdir('../output/DR-Net_triplet_loss')\n",
    "\n",
    "NB_EPOCH = 30\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "AUGMENTATION = True\n",
    "\n",
    "# Change this for MNIST (Notebook: DR-Net_contrastive_loss)\n",
    "\"\"\"\n",
    "train_x, train_y = np.load('data/train_x.npy'), np.load('data/train_y.npy')\n",
    "test_x, test_y = np.load('data/test_x.npy'), np.load('data/test_y.npy')\n",
    "\"\"\"\n",
    "# the data, split between train and test sets\n",
    "(train_x, train_y), (test_x, test_y) = mnist.load_data()\n",
    "train_x = train_x.astype('float32')\n",
    "test_x = test_x.astype('float32')\n",
    "train_x /= 255\n",
    "test_x /= 255\n",
    "\n",
    "n_subjects = len(set(train_y))\n",
    "n_train = train_x.shape[0]\n",
    "n_test = test_x.shape[0]\n",
    "\n",
    "One = OneHotEncoder()\n",
    "One.fit(train_y.reshape(-1, 1))\n",
    "\n",
    "train_y = One.transform(train_y.reshape(-1, 1)).todense()\n",
    "test_y = One.transform(test_y.reshape(-1, 1)).todense()\n",
    "\n",
    "print('n_train: {}'.format(n_train))\n",
    "print('n_test: {}'.format(n_test))\n",
    "print('n_subjects: {}'.format(n_subjects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-32c9f02123e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mMODEL_IMAGE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOUT_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Net_triplet_loss.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mWEIGHTS_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'data/weights/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWEIGHTS_DIR\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'weights.best.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m datagen = ImageDataGenerator(\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "MODEL_IMAGE = os.path.join(OUT_DIR, 'Net_triplet_loss.png')\n",
    "WEIGHTS_DIR = os.path.join(OUT_DIR, 'weights.best.h5')\n",
    "\n",
    "checkpoint = ModelCheckpoint(WEIGHTS_DIR, monitor='val_acc', verbose=0, save_best_only=True, mode='max')\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "model = build_my_cnn(train_x.shape[1], n_subjects, train_x.shape[2])  # default=227\n",
    "model.summary()\n",
    "\n",
    "plot_model(model, to_file=MODEL_IMAGE, show_shapes=True)\n",
    "image_disp(filename=MODEL_IMAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(datagen.flow(train_x, train_y, batch_size=BATCH_SIZE),\n",
    "                        samples_per_epoch=train_x.shape[0],\n",
    "                        nb_epoch=NB_EPOCH,\n",
    "                        validation_data=[test_x, test_y],\n",
    "                        callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train the model with triplet loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_scores(data_y, protocol):\n",
    "    data_y = data_y / np.linalg.norm(data_y, axis=1)[:, np.newaxis]\n",
    "    scores = data_y @ data_y.T\n",
    "\n",
    "    return scores[protocol], scores[np.logical_not(protocol)]\n",
    "\n",
    "\n",
    "def calc_metrics(targets_scores, imposter_scores):\n",
    "    min_score = np.minimum(np.min(targets_scores), np.min(imposter_scores))\n",
    "    max_score = np.maximum(np.max(targets_scores), np.max(imposter_scores))\n",
    "\n",
    "    n_tars = len(targets_scores)\n",
    "    n_imps = len(imposter_scores)\n",
    "\n",
    "    N = 100\n",
    "\n",
    "    fars = np.zeros((N,))\n",
    "    frrs = np.zeros((N,))\n",
    "    dists = np.zeros((N,))\n",
    "\n",
    "    min_gap = float('inf')\n",
    "    eer = 0\n",
    "\n",
    "    for i, dist in enumerate(np.linspace(min_score, max_score, N)):\n",
    "        far = len(np.where(imposter_scores > dist)[0]) / n_imps\n",
    "        frr = len(np.where(targets_scores < dist)[0]) / n_tars\n",
    "        fars[i] = far\n",
    "        frrs[i] = frr\n",
    "        dists[i] = dist\n",
    "\n",
    "        gap = np.abs(far - frr)\n",
    "\n",
    "        if gap < min_gap:\n",
    "            min_gap = gap\n",
    "            eer = (far + frr) / 2\n",
    "\n",
    "    return eer, fars, frrs, dists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "#from model import build_my_cnn\n",
    "#from model import build_tpe\n",
    "#from model import Bottleneck\n",
    "#from identification import get_scores, calc_metrics\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "n_in = 24\n",
    "n_out = 24\n",
    "\n",
    "data_dir='data/'\n",
    "\n",
    "cnn = build_my_cnn(227, 24)\n",
    "cnn.load_weights(data_dir+'weights/weights.best.h5')\n",
    "bottleneck = Bottleneck(cnn, ~1)\n",
    "\n",
    "train_x, train_y = np.load(data_dir+'train_x.npy'), np.load(data_dir+'train_y.npy')\n",
    "test_x, test_y = np.load(data_dir+'test_x.npy'), np.load(data_dir+'test_y.npy')\n",
    "\n",
    "train_x = np.vstack([train_x, test_x])\n",
    "train_y = np.hstack([train_y, test_y])\n",
    "\n",
    "dev_x = np.load(data_dir+'dev_x.npy')\n",
    "dev_protocol = np.load(data_dir+'dev_protocol.npy')\n",
    "\n",
    "train_emb = bottleneck.predict(train_x, batch_size=256)\n",
    "dev_emb = bottleneck.predict(dev_x, batch_size=256)\n",
    "\n",
    "del train_x\n",
    "\n",
    "pca = PCA(n_out)\n",
    "pca.fit(train_emb)\n",
    "W_pca = pca.components_\n",
    "\n",
    "tpe, tpe_pred = build_tpe(n_in, n_out, W_pca.T)\n",
    "# tpe.load_weights('data/weights/weights.tpe.mineer.h5')\n",
    "\n",
    "train_y = np.array(train_y)\n",
    "subjects = list(set(train_y))\n",
    "\n",
    "anchors_inds = []\n",
    "positives_inds = []\n",
    "labels = []\n",
    "\n",
    "for subj in subjects:\n",
    "    mask = train_y == subj\n",
    "    inds = np.where(mask)[0]\n",
    "    for a, p in itertools.permutations(inds, 2):\n",
    "        anchors_inds.append(a)\n",
    "        positives_inds.append(p)\n",
    "        labels.append(subj)\n",
    "\n",
    "anchors = train_emb[anchors_inds]\n",
    "positives = train_emb[positives_inds]\n",
    "n_anchors = len(anchors_inds)\n",
    "\n",
    "NB_EPOCH = 100\n",
    "COLD_START = NB_EPOCH\n",
    "BATCH_SIZE = 4\n",
    "BIG_BATCH_SIZE = 512\n",
    "\n",
    "inds = np.arange(n_anchors)\n",
    "\n",
    "def get_batch(hard=False):\n",
    "    batch_inds = np.random.choice(inds, size=BIG_BATCH_SIZE, replace=False)\n",
    "\n",
    "    train_emb2 = tpe_pred.predict(train_emb, batch_size=1024)\n",
    "    scores = train_emb2 @ train_emb2.T\n",
    "    negative_inds = []\n",
    "\n",
    "    for i in batch_inds:\n",
    "        label = labels[i]\n",
    "        mask = train_y == label\n",
    "        if hard:\n",
    "            negative_inds.append(np.ma.array(scores[label], mask=mask).argmax())\n",
    "        else:\n",
    "            negative_inds.append(np.random.choice(np.where(np.logical_not(mask))[0], size=1)[0])\n",
    "\n",
    "    return anchors[batch_inds], positives[batch_inds], train_emb[negative_inds]\n",
    "\n",
    "\n",
    "def test():\n",
    "    dev_emb2 = tpe_pred.predict(dev_emb)\n",
    "    tsc, isc = get_scores(dev_emb2, dev_protocol)\n",
    "    eer, _, _, _ = calc_metrics(tsc, isc)\n",
    "    return eer\n",
    "\n",
    "z = np.zeros((BIG_BATCH_SIZE,))\n",
    "\n",
    "mineer = float('inf')\n",
    "\n",
    "for e in range(NB_EPOCH):\n",
    "    print('epoch: {}'.format(e))\n",
    "    a, p, n = get_batch(e > COLD_START)\n",
    "    tpe.fit([a, p, n], z, batch_size=BATCH_SIZE, epochs=1)\n",
    "    eer = test()\n",
    "    print('EER: {:.2f}'.format(eer * 100))\n",
    "    if eer < mineer:\n",
    "        mineer = eer\n",
    "        tpe.save_weights(data_dir+'weights/weights.tpe.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import numpy as np\n",
    "from preprocessing import FaceDetector, FaceAligner, clip_to_range\n",
    "import keras.backend as K\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.layers import Dense, Lambda, Input, merge, Conv2D, Activation, Dropout, MaxPooling2D, Flatten, GlobalMaxPooling2D, BatchNormalization\n",
    "\n",
    "GREATER_THAN = 32\n",
    "BATCH_SIZE = 128\n",
    "IMSIZE = 217\n",
    "IMBORDER = 5\n",
    "\n",
    "def build_my_cnn(dim,n_class):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(BatchNormalization(input_shape=(dim,dim,3)))\n",
    "    \n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(128,kernel_size=(3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(32, kernel_size=(3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(GlobalMaxPooling2D())\n",
    "    \n",
    "    model.add(Dense(64)) #512\n",
    "    model.add(Activation('relu'))    \n",
    "    \n",
    "    model.add(Dense(n_class))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def triplet_loss(y_true, y_pred):\n",
    "    return -K.mean(K.log(K.sigmoid(y_pred)))\n",
    "\n",
    "def triplet_merge(inputs):\n",
    "    a, p, n = inputs\n",
    "    return K.sum(a * (p - n), axis=1)\n",
    "\n",
    "def triplet_merge_shape(input_shapes):\n",
    "    return (input_shapes[0][0], 1)\n",
    "\n",
    "def build_tpe(n_in, n_out, W_pca=None):\n",
    "    a = Input(shape=(n_in,))\n",
    "    p = Input(shape=(n_in,))\n",
    "    n = Input(shape=(n_in,))\n",
    "\n",
    "    if W_pca is None:\n",
    "        W_pca = np.zeros((n_in, n_out))\n",
    "\n",
    "    base_model = Sequential()\n",
    "    base_model.add(Dense(n_out, input_dim=n_in, bias=False, weights=[W_pca], activation='linear'))\n",
    "    base_model.add(Lambda(lambda x: K.l2_normalize(x, axis=1)))\n",
    "\n",
    "    a_emb = base_model(a)\n",
    "    p_emb = base_model(p)\n",
    "    n_emb = base_model(n)\n",
    "\n",
    "    e = merge([a_emb, p_emb, n_emb], mode=triplet_merge, output_shape=triplet_merge_shape)\n",
    "\n",
    "    model = Model(input=[a, p, n], output=e)\n",
    "    predict = Model(input=a, output=a_emb)\n",
    "\n",
    "    model.compile(loss=triplet_loss, optimizer='rmsprop')\n",
    "\n",
    "    return model, predict\n",
    "\n",
    "class Bottleneck:\n",
    "    def __init__(self, model, layer):\n",
    "        self.fn = K.function([model.layers[0].input, K.learning_phase()], [model.layers[layer].output])\n",
    "\n",
    "    def predict(self, data_x, batch_size=32, learning_phase=False):\n",
    "        n_data = len(data_x)\n",
    "        n_batches = n_data // batch_size + (0 if n_data % batch_size == 0 else 1)\n",
    "\n",
    "        result = None\n",
    "\n",
    "        learning_phase = 1 if learning_phase else 0\n",
    "\n",
    "        for i in range(n_batches):\n",
    "            batch_x = data_x[i * batch_size:(i + 1) * batch_size]\n",
    "            batch_y = self.fn([batch_x, 0])[0]\n",
    "\n",
    "            if result is None:\n",
    "                result = batch_y\n",
    "            else:\n",
    "                result = np.vstack([result, batch_y])\n",
    "\n",
    "        return result\n",
    "\n",
    "class FaceVerificator:\n",
    "    def __init__(self, model_dir):\n",
    "        self._model_dir = model_dir\n",
    "\n",
    "        self._model_files = {\n",
    "            'shape_predictor': os.path.join(model_dir, 'shape_predictor_68_face_landmarks.dat'),\n",
    "            'face_template': os.path.join(model_dir, 'face_template.npy'),\n",
    "            'mean': os.path.join(model_dir, 'mean.npy'),\n",
    "            'stddev': os.path.join(model_dir, 'stddev.npy'),\n",
    "            'cnn_weights': os.path.join(model_dir, 'weights_cnn.h5'),\n",
    "            'tpe_weights': os.path.join(model_dir, 'weights_tpe.h5'),\n",
    "        }\n",
    "\n",
    "    def initialize_model(self):\n",
    "        self._mean = np.load(self._model_files['mean'])\n",
    "        self._stddev = np.load(self._model_files['stddev'])\n",
    "        self._fd = FaceDetector()\n",
    "        self._fa = FaceAligner(self._model_files['shape_predictor'],\n",
    "                               self._model_files['face_template'])\n",
    "        cnn = build_my_cnn(227, 24)\n",
    "        cnn.load_weights(self._model_files['cnn_weights'])\n",
    "        self._cnn = Bottleneck(cnn, ~1)\n",
    "        _, tpe = build_tpe(24, 24)\n",
    "        tpe.load_weights(self._model_files['tpe_weights'])\n",
    "        self._tpe = tpe\n",
    "\n",
    "    def normalize(self, img):\n",
    "        img = clip_to_range(img)\n",
    "        return (img - self._mean) / self._stddev\n",
    "\n",
    "    def process_image(self, img):\n",
    "        face_rects = self._fd.detect_faces(img, upscale_factor=2, greater_than=GREATER_THAN)\n",
    "\n",
    "        if not face_rects:\n",
    "            return []\n",
    "\n",
    "        faces = self._fa.align_faces(img, face_rects, dim=IMSIZE, border=IMBORDER)\n",
    "        faces = list(map(self.normalize, faces))\n",
    "\n",
    "        faces_y = self._cnn.predict(faces, batch_size=BATCH_SIZE)\n",
    "        faces_y = self._tpe.predict(faces_y, batch_size=BATCH_SIZE)\n",
    "\n",
    "        return list(zip(face_rects, faces_y))\n",
    "\n",
    "    def compare_many(self, dist, xs, ys):\n",
    "        xs = np.array(xs)\n",
    "        ys = np.array(ys)\n",
    "        scores = xs @ ys.T\n",
    "        return scores, scores > dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from model import FaceVerificator\n",
    "from skimage import io\n",
    "\n",
    "###\n",
    "img_path_0 = 'data/dev/21.jpg'\n",
    "img_path_1 = 'data/dev/22.jpg'\n",
    "dist = 0.85\n",
    "###\n",
    "\n",
    "extractor = FaceVerificator('model')\n",
    "extractor.initialize_model()\n",
    "\n",
    "img_0 = io.imread(img_path_0)\n",
    "img_1 = io.imread(img_path_1)\n",
    "\n",
    "faces_0 = extractor.process_image(img_0)\n",
    "faces_1 = extractor.process_image(img_1)\n",
    "\n",
    "n_faces_0 = len(faces_0)\n",
    "n_faces_1 = len(faces_1)\n",
    "\n",
    "if n_faces_0 == 0 or n_faces_1 == 0:\n",
    "    print('Error: No faces found on the {}!'.format(img_path_0 if n_faces_0 == 0 else img_path_1))\n",
    "    exit()\n",
    "\n",
    "rects_0 = list(map(lambda p: p[0], faces_0))\n",
    "rects_1 = list(map(lambda p: p[0], faces_1))\n",
    "\n",
    "embs_0 = list(map(lambda p: p[1], faces_0))\n",
    "embs_1 = list(map(lambda p: p[1], faces_1))\n",
    "\n",
    "scores, comps = extractor.compare_many(dist, embs_0, embs_1)\n",
    "\n",
    "print('Rects on image 0: {}'.format(rects_0))\n",
    "print('Rects on image 1: {}'.format(rects_1))\n",
    "\n",
    "print('Embeddings of faces on image 0:')\n",
    "print(embs_0)\n",
    "\n",
    "print('Embeddings of faces on image 1:')\n",
    "print(embs_1)\n",
    "\n",
    "print('Score matrix:')\n",
    "print(scores)\n",
    "\n",
    "print('Decision matrix :')\n",
    "print(comps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
